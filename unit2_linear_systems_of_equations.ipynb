{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869c44c5-e11d-458c-8181-a9be6afb8e70",
   "metadata": {},
   "source": [
    "## Unit 2 - Linear Systems of Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c3e93-c99d-4628-b2d4-6ab2bf146bfe",
   "metadata": {},
   "source": [
    "### Linear Systems\n",
    "\n",
    "A linear system of $m$ equations in $n$ uknowns has the forms:\n",
    "\n",
    "$a_{11}x_1 + a_{12}x_2 + ... + a_{1n}x_n = b_{1}$\\\n",
    "$a_{21}x_1 + a_{22}x_2 + ... + a_{2n}x_n = b_{2}$\\\n",
    "$.$\\\n",
    "$.$\\\n",
    "$.$\\\n",
    "$a_{m1}x_1 + a_{m2}x_2 + ... + a_{mn}x_n = b_{m}$\n",
    "\n",
    "$x$'s are unknowns, $a$'s and $b$ are known. There are $m$ equations.\n",
    "\n",
    "Solving systems of these equations is the focus of this unit. \n",
    "\n",
    "This system can also be succinctly expressed as a matrix equation: \\\n",
    "$Ax = b$ \\\n",
    "where $A$ is the matrix of coefficients, $x$ is a vector of unknowns, $b$ is a vector of constants. More specifically:\\\n",
    "$A = [a_{ij}]_{i=1..m,j=1..n}$\\\n",
    "$x = [x_1, x_2, ... x_n]$\\\n",
    "$b = [b_1, b_2, ... b_m]$\n",
    "\n",
    "We can also express this linear systems using an augmented matrix.\\\n",
    "$[A|b]$ (this is just shorthand that allows you to skip writing the $x$s)\n",
    "\n",
    "Examples:\n",
    "\n",
    "1) $x_1 + x_2 = 4$ \\\n",
    "   $x_1 - x_2 = 2$ \n",
    "\n",
    "2) $ \\left[\\begin{matrix} 1 & 1 \\\\ 1 & -1 \\end{matrix}\\right]\n",
    "\\left(\\begin{matrix} x_1 \\\\ x_2 \\end{matrix}\\right)\n",
    "=\n",
    "\\left(\\begin{matrix} 4 \\\\ 2 \\end{matrix}\\right)\n",
    "$ (This shows that the matrix-vector product of the coefficient matrix and the vector of unknowns gives the solution [[4],[2]] )\n",
    "\n",
    "3) $ \\left[\\begin{matrix} 1 & 1 & | & 4 \\\\ 1 & -1 & | & 2 \\end{matrix}\\right]$\n",
    "\n",
    "All three ways represent the same linear system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64133c6e-3b18-4bfc-bd78-a9e89890c439",
   "metadata": {},
   "source": [
    "### Types of Linear Systems\n",
    "\n",
    "#### Underconstrained Linear System\n",
    "$ \\left[\\begin{matrix}  &  &  &  & | \\\\  &  &  &  & | \\end{matrix}\\right]$\n",
    "\n",
    "Typically the number of rows is less than the number of columns ($m<n$). There are an infinite number of solutions. There are many more variables than there are equations. \n",
    "\n",
    "Example:\n",
    "\n",
    "$ \\left[\\begin{matrix} 1 & 2 & | & 3 \\\\ 0 & 0 & | & 0 \\end{matrix}\\right]$\n",
    "\n",
    "$x_1 + 2x_2 = 3$\\\n",
    "$0x_1 + 0x_2 = 0$\n",
    "\n",
    "There is an infinite number of solutions that can be expressed as \\\n",
    "$\\left(\\begin{matrix} x_1 \\\\ x_2 \\end{matrix}\\right)$ such that $x_1 + 2x_2 = 3$\n",
    "\n",
    "An underconstrained system with $m<n$ can be augmented byy rows of 0's to make it square (perfect).\n",
    "\n",
    "#### Perfectly Constrained\n",
    "$ \\left[\\begin{matrix}  &  &  &  & | \\\\  &  &  &  & | \\\\  &  &  &  & |\\end{matrix}\\right]$\n",
    "\n",
    "Typically, $m=n$. One unique solution.\n",
    "\n",
    "Example:\n",
    "\n",
    "$ \\left[\\begin{matrix} 1 & 0 & | & 3 \\\\ 0 & 2 & | & 0 \\end{matrix}\\right]$\n",
    "\n",
    "$x_1 + 0x_2 = 3$\\\n",
    "$0x_1 + 2x_2 = 0$\n",
    "\n",
    "There is a unique solution that can be expressed as \\\n",
    "$\\left(\\begin{matrix} x_1 \\\\ x_2 \\end{matrix}\\right)$ = $\\left(\\begin{matrix} 3 \\\\ 0 \\end{matrix}\\right)$\n",
    "\n",
    "Our attention to linear systems will focus on Perfectly Constrained systems where $m=n$\n",
    "\n",
    "#### Over Constrained\n",
    "$ \\left[\\begin{matrix}  &  &  &  & | \\\\  &  &  &  & | \\\\  &  &  &  & | \\\\  &  &  &  & | \\\\  &  &  &  & | \\end{matrix}\\right]$\n",
    "\n",
    "Typically, $m>n$. There is no solution.\n",
    "\n",
    "Example:\n",
    "\n",
    "$ \\left[\\begin{matrix} 1 & 0 & | & 3 \\\\ 2 & 0 & | & 0 \\end{matrix}\\right]$\n",
    "\n",
    "$1x_1 + 0x_2 = 3$\\\n",
    "$2x_1 + 0x_2 = 0$\n",
    "\n",
    "There is no solution since these equations are inconsistent.\n",
    "\n",
    "$x_1 = 3$\\\n",
    "2x_1 = 0\n",
    "\n",
    "This is a very common case in data science. Number of features is usually much less than data points so there's not exact solution. In this case you want to find some weighting of features that is a best fit. You can get a good approximate solution to over constrained systems by solving a related system with a square matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7d5f42-87fb-471d-8052-900fb1f07cbd",
   "metadata": {},
   "source": [
    "### Solving Linear Systems by Direct Methods\n",
    "\n",
    "Three operations on linear systems that do not change the solution\n",
    "\n",
    "1) Multiply an equation by a non-zero constant\n",
    "2) Exchange the order of two equations\n",
    "3) Replace an equation with the sum of itself and a constant multiple of another equation\n",
    "\n",
    "Example\n",
    "\n",
    "$x_1 + x_2 = 4$\\\n",
    "$x_1 - x_2 = 2$\n",
    "\n",
    "Same solution as the following equations:\n",
    "\n",
    "By #1\\\n",
    "$2x_1 + 2x_2 = 8$ (multiplied this equation by 2)\\\n",
    "$x_1-x_2=2$\n",
    "\n",
    "By #2 (just swap the order of the equations)\\\n",
    "$x_1 - x_2 = 2$\\\n",
    "$2x_1 + 2x_2 = 8$\\\n",
    "\n",
    "By #3\\\n",
    "$x_1 - x_2 = 2$\\\n",
    "$2x_1 + 2x_2 = 8 = eq_2 = eq_2 - 2eq_1$ (replace equation 2 with a constant multiple of another equation. in this case $eq_2 = eq_2 - 2eq_1$\\\n",
    "This gives the following new equations:\\\n",
    "$x_1 - x_2 = 2$\\\n",
    "$0 + 4x_2 = 4$\n",
    "\n",
    "These operations don't need to be applied in order - this was just an example.\n",
    "\n",
    "#### Elementary Row Operations on Augmented Matrices\n",
    "\n",
    "1) $R_i \\leftarrow cR_i$ (Replace $Row_i$ with a consant $c$ times $Row_i$)\n",
    "\n",
    "2) $R_i \\leftarrow\\rightarrow R_j$ (Swap rows i and j)\n",
    "\n",
    "3) $R_i \\leftarrow R_i + aR_j$ (replace row i with row i + a time row j)\n",
    "\n",
    "Example (same problem from above example)\n",
    "\n",
    "$x_1 + x_2 = 4$\\\n",
    "$x_1 - x_2 = 2$\n",
    "\n",
    "$ \\left[\\begin{matrix} 1 & 1 & | & 4 \\\\ 1 & -1 & | & 2 \\end{matrix}\\right] \\rightarrow \\left[\\begin{matrix} 1 & 1 & | & 4 \\\\ 0 & -2 & | & -2 \\end{matrix}\\right]$\n",
    "\n",
    "Using operation #3, we can replace the second equation with the sum of the equation and constant multiple of another equation (in this case, -1). Multiplying equation 1 by -1 gives $-x_1 - x_2 = - 4$. \n",
    "\n",
    "Then, $R_2 - R_1 = x_1 - x_1 -x_2 - x_2 = -4 + 2$\n",
    "\n",
    "$R_2 \\leftarrow R_2 - R_1$ (this is the notation used for the operation above. It means \"replace row 2 with row 2 - row 1)\n",
    "\n",
    "The second equation can now be rewritten as\n",
    "\n",
    "$-2x_2 = -2 $ \\\n",
    "So $x_2 = 1$\n",
    "\n",
    "Now, going back to the first equation:\n",
    "\n",
    "$x_1 + 1 = 4$\\\n",
    "$x_1 = 3$\n",
    "\n",
    "$\\left(\\begin{matrix} x_1 \\\\ x_2 \\end{matrix}\\right) = \\left(\\begin{matrix} 3 \\\\ 1\\end{matrix}\\right)$\n",
    "\n",
    "Solving this system of equations amounts to finding the vector of unknowns such that the vector product of the given matrix and the vector of unknowns give ( [[4],[2]]). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0132925f-5c88-4007-84db-fe2f99ce00e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# In python\n",
    "\n",
    "given_matrix = [[1,1],[1,-1]]\n",
    "matrix_of_unknowns = [[3],[1]]\n",
    "solution = [[4],[2]]\n",
    "\n",
    "result = np.dot(given_matrix, matrix_of_unknowns)  #matrix-vector product\n",
    "print(result)\n",
    "assert np.array_equal(result, solution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4e932-97b9-4c30-b6b1-a253fc6d332f",
   "metadata": {},
   "source": [
    "### Gaussian Elimination with Backward Substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68c9c4f-4480-45fc-8d44-d006df19c32b",
   "metadata": {},
   "source": [
    "Specific method that can be applied to a square coefficient matrix\n",
    "\n",
    "Given an augmented matrix $[A,|b]$ with $A \\in \\mathbb{R}^{m*n}$\n",
    "\n",
    "Step 1 (Gaussian Elimination) - Row reduce $[A|b]$ to get $[U|b']$ where $U$ is upper triangular with nonzero diagonal entries.\n",
    "\n",
    "$U$ = \n",
    "$ \\left[\\begin{matrix} x & x & x & x \\\\ 0 & x & x & x \\\\ 0 & 0 & x & x \\\\ 0 & 0 & 0 & x \\end{matrix}\\right]$ = all the information in $U$ is in the upper right triangular area.\n",
    "\n",
    "Step 2 (Backward Substitution) - Iteratively solve for $x$ in the order $x_x, x_{n-1}, ... x_1$\n",
    "\n",
    "Example:\n",
    "\n",
    "$ \\left[\\begin{matrix} 1 & 1 & 1 & | & 6 \\\\ -1 & 1 & 1 & | & 4 \\\\ 2 & -1 & 1 & | & 3\\end{matrix}\\right]$\n",
    "\n",
    "**Step 1 Gaussian Elimination** - Turn the bottom left 3 entries into $0$s. \"Use the top left element ($a_{11}$ - the very top left 1) as a pivot against row 2 and row 3. \"\n",
    "\n",
    "$Row_2 \\leftarrow Row_2 + Row_1$ (Replace row2 with row2+row1)\\\n",
    "$Row_3 \\leftarrow $Row_3 - 2*Row_1$ (Replace row3 with row3 - 2 times row1)\n",
    "\n",
    "That gives:\n",
    "\n",
    "$\\left[\\begin{matrix} 1 & 1 & 1 & | & 6 \\\\ 0 & 2 & 2 & | & 10 \\\\ 0 & -3 & -1 & | & -9\\end{matrix}\\right]$\n",
    "\n",
    "Gaussian elimination always says to use the diagonal row as the pivot, so here we pivot on $Row_2$\n",
    "\n",
    "$Row_3 \\rightarrow Row_3 + 3/2*Row_2$\n",
    "\n",
    "That gives:\n",
    "\n",
    "$\\left[\\begin{matrix} 1 & 1 & 1 & | & 6 \\\\ 0 & 2 & 2 & | & 10 \\\\ 0 & 0 & 2 & | & 6\\end{matrix}\\right]$\n",
    "\n",
    "That completes the Guassian Elimination piece.\n",
    "\n",
    "**Step 2 Backward Substitution**: \n",
    "\n",
    "Solve for x_3 (the final row in the matrix): \\\n",
    "$2x_3 = 6$\\\n",
    "$x_3 = 3$\n",
    "\n",
    "Solve for x_2:\\\n",
    "$2x_2 + 2x_3 = 10 $\\\n",
    "$2x_2 + 2*3 = 10$ (replace x_3 with 3 solved in the previous step)\\\n",
    "$2x_2 = 4$\\\n",
    "$x_2 = 2$\n",
    "\n",
    "Solve for x_1:\\\n",
    "$x_1 + x_2 + x_3 = 6$\\\n",
    "$x_1 + 2 + 3 = 6$\\\n",
    "$x_1 = 1$\n",
    "\n",
    "So, the solution vector is:\n",
    "\n",
    "$\\vec{x} = \\left(\\begin{matrix} x_1 \\\\ x_2 \\\\ x_3\\end{matrix}\\right)$ = $\\left(\\begin{matrix} 1 \\\\ 2 \\\\ 3\\end{matrix}\\right)$\n",
    "\n",
    "The pseudocode for these algorithms is very simple. \n",
    "\n",
    "**Gaussian Elimination Algorithm**:\n",
    "\n",
    "Input $[A|b]$, $A \\in \\mathbb{R}^{m*n}$, $b \\in \\mathbb{R}^n$\\\n",
    "Output $[U|b']$, $U \\in \\mathbb{R}^{m*n}$, $b' \\in \\mathbb{R}^n$ and $U$ is upper triangular: $U_{ij} = 0$ for $i > j$ and nondiagonal: $U_{jj} != 0$ for all $j$\n",
    "\n",
    "For columns $j = 1$ to $n$:\\\n",
    "&nbsp;&nbsp;If $a_{jj} == 0$, Output FAIL\\\n",
    "&nbsp;&nbsp;For rows $i > j$\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;$Row_i \\rightarrow Row_i + (a_{ij} / a_{jj}) * Row_j$ (this says $a_{ij}$ divided by $a_{jj}$)\\\n",
    "&nbsp;&nbsp;Output Resulting $[U,b']$\n",
    "\n",
    "**Backward Substituion Algorithm**:\n",
    "\n",
    "Input $[U,b']$\n",
    "Ouput $x \\in \\mathbb{R}^n$\n",
    "\n",
    "For $i = n$ to $1$\\\n",
    "&nbsp;&nbsp;$x_i = (b_i - \\sum_{j>i}^na_{ij}x_j) / a_{ii}$\\\n",
    "Output x\n",
    "\n",
    "**Run Times:**\n",
    "\n",
    "The Gaussian Elimination algorithm works in $n^3$ time\\\n",
    "The Backward Substitution algorithm works in $n^2$ time\n",
    "\n",
    "Gaussian Elimination is very straightforward, but we e need faster, and possibly less straighforward, methods to solve this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2ad8b1bb-6f7f-4c0d-a7c7-6a27eb5195e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Elimination is [[1, 1, 1], array([0., 2., 2.]), array([0., 0., 2.])]\n",
      "Backward Substitution is [1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gaussian_elimination(A):\n",
    "    for j in range(len(A[0])):\n",
    "        if A[j][j] == 0:\n",
    "            return -1 # ERROR\n",
    "        for i in range(j+1, len(A)):\n",
    "            A[i] = np.add(A[i], np.multiply(-A[i][j] / A[j][j], A[j]))\n",
    "            # in the above, the algorithm explained in the \n",
    "            # lecture did not include the negative in the -A[i][j]\n",
    "            # but it seems to be right\n",
    "    return A\n",
    "\n",
    "A = [[ 1,  1, 1],\n",
    "     [-1,  1, 1],\n",
    "     [ 2, -1, 1]]\n",
    "A_answer = [[1.,1.,1.],[0.,2.,2.],[0.,0.,2.]]\n",
    "\n",
    "assert gaussian_elimination([[0,0,0],[0,0,0]]) == -1\n",
    "assert np.array_equal(gaussian_elimination(A), A_answer)\n",
    "\n",
    "print(f'Gaussian Elimination is {gaussian_elimination(A)}')\n",
    "\n",
    "def backward_substitution(U, b_prime):\n",
    "    x = [0 for i in range(len(U))]\n",
    "    for i in range(len(U)-1,-1,-1):\n",
    "        row_sum = 0\n",
    "        for j in range(len(U[0])):\n",
    "            row_sum = row_sum + U[i][j]*x[j]\n",
    "        x[i] = (b_prime[i] - row_sum) / U[i][i]\n",
    "    return x\n",
    "\n",
    "b_prime = [6,10,6]\n",
    "x_answer = [1.,2.,3.]\n",
    "\n",
    "print(f'Backward Substitution is {backward_substitution(gaussian_elimination(A), b_prime)}')\n",
    "assert np.array_equal(backward_substitution(gaussian_elimination(A), b_prime), x_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea91bb27-e41b-4f15-b4a5-2e57d55b5c9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Elementary Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a34fc6-97eb-4a73-8981-df8caf7b5a13",
   "metadata": {},
   "source": [
    "The elementary row operations previously introduced that do not change the solution to a linear system can be accomplished by matrix multiplication.\n",
    "\n",
    "**Type 1 Operations:** $Row_i \\leftarrow cRow_i$\n",
    "\n",
    "\n",
    "$\\left[\\begin{matrix} & & & &\\\\ x & x & x & x \\\\ & & & & \\end{matrix}\\right]$\n",
    "$\\rightarrow$ c\n",
    "$\\left[\\begin{matrix} &  & & &\\\\ cx & cx & cx & cx \\\\ & & & & \\end{matrix}\\right]$\n",
    "\n",
    "Take the $i$th row, and multiply the constant $c$ by the whole row.\n",
    "\n",
    "We claim there's some elementary matrix that accomplishes the same thing as the row operation described above.\n",
    "\n",
    "What is that matrix? It's this one:\n",
    "\n",
    "Explanation: If the $c$ weren't in the leftmost matrix, it would just be the identity matrix and would just give the original matrix as the result. Having $c$ in the identity matrix will multiply $c$ against the $i$th row of the original matric (since $c$ is in the $i$th row).  \n",
    "\n",
    "$\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & c & 0  \\\\ 0 & 0 & 1 \\end{matrix}\\right]$\n",
    "$\\left[\\begin{matrix} &  &  & &  \\\\ x & x & x & x \\\\  &  &  & & \\end{matrix}\\right]$\n",
    "$\\rightarrow$ c\n",
    "$\\left[\\begin{matrix} &  &  & &  \\\\ x & x & x & x \\\\  &  &  & & \\end{matrix}\\right]$\n",
    "\n",
    "**Type 2 Operations:** $Row_i \\leftarrow\\rightarrow Row_j$\n",
    "\n",
    "Replace the $ii$th entry and the $jj$th entry with 0's and place a 1 in the $ij$th position and the $ji$th position.\n",
    "\n",
    "$\\left[\\begin{matrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0  \\\\ 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 \\end{matrix}\\right]$\n",
    "$\\left[\\begin{matrix} & & & & & \\\\ i & i & i & i & i \\\\ & & & & & \\\\ j & j & j & j & j & \\\\ & & & & & \\end{matrix}\\right]$\n",
    "$\\rightarrow$\n",
    "$\\left[\\begin{matrix} &  & & & &\\\\ j & j & j & j &j\\\\ & & & & &\\\\ i& i& i& i& i& \\\\ & & & & & \\end{matrix}\\right]$\n",
    "\n",
    "**Type 3 Operations:** $Row_i \\leftarrow Row_i + cRow_j$\n",
    "\n",
    "Below, $c$ is in the $ij$th row ($i$ is rows, $j$ is columns). This has the effect of multiplying the $jth$ row by $c$ and placing that result in the $i$th row of the resulting matrix. \n",
    "\n",
    "$\\left[\\begin{matrix} 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0  \\\\ 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & c & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 \\end{matrix}\\right]$\n",
    "$\\left[\\begin{matrix} & & & & & \\\\ i & i & i & i & i \\\\ & & & & & \\\\ j & j & j & j & j & \\\\ & & & & & \\end{matrix}\\right]$\n",
    "$\\rightarrow$\n",
    "$\\left[\\begin{matrix} &  & & & &\\\\ cj & cj & cj & cj &cj\\\\ & & & & &\\\\ j& j& j& j& j& \\\\ & & & & & \\end{matrix}\\right]$\n",
    "\n",
    "Examples:\n",
    "\n",
    "$E_1$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 1 & 0  \\\\ 0 & 0 & 2 \\end{matrix}\\right]$ (Type 1 Elementary Matrix)\n",
    "\n",
    "$E_2$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 0 & 1  \\\\ 0 & 1 & 0 \\end{matrix}\\right]$ (Type 2 Elementary Matrix)\n",
    "\n",
    "$E_3$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 1 & 1  \\\\ 0 & 2 & 1 \\end{matrix}\\right]$\n",
    "(Type 3 Elementary Matrix)\n",
    "\n",
    "$A$ = $\\left[\\begin{matrix} 1& 2 & 3  \\\\ 4 & 5 & 6  \\\\ 7 &8 & 9 \\end{matrix}\\right]$ \n",
    "\n",
    "By Matrix Multiplication:\n",
    "\n",
    "$E_1A$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 1 & 0  \\\\ 0 & 0 & 2 \\end{matrix}\\right]$ $\\left[\\begin{matrix} 1& 2 & 3  \\\\ 4 & 5 & 6  \\\\ 7 &8 & 9 \\end{matrix}\\right]$ = $\\left[\\begin{matrix} 1& 2 & 3  \\\\ 4 & 5 & 6  \\\\ 14 & 16 & 18 \\end{matrix}\\right]$ $Row_3 \\leftarrow cRow_3$ where $c=2$\n",
    "\n",
    "$E_2A$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 0 & 1  \\\\ 0 & 1 & 0 \\end{matrix}\\right]$ $\\left[\\begin{matrix} 1& 2 & 3  \\\\ 4 & 5 & 6  \\\\ 7 &8 & 9 \\end{matrix}\\right]$ = \n",
    "$\\left[\\begin{matrix} 1& 2 & 3  \\\\ 7 & 8 & 9  \\\\ 4 & 5 & 6 \\end{matrix}\\right]$ $Row_3 \\leftarrow\\rightarrow Row_2$\n",
    "\n",
    "$E_3A$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 1 & 0  \\\\ 0 & 2 & 1 \\end{matrix}\\right]$ $\\left[\\begin{matrix} 1& 2 & 3  \\\\ 4 & 5 & 6  \\\\ 7 &8 & 9 \\end{matrix}\\right]$ = \n",
    "$\\left[\\begin{matrix} 1& 2 & 3  \\\\ 4 & 5 & 6  \\\\ 15 & 18 & 21 \\end{matrix}\\right]$ $Row_3 \\leftarrow Row_3 + 2Row_2$\n",
    "\n",
    "To undo and elementary operation:\n",
    "\n",
    "$E_1$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 1 & 0  \\\\ 0 & 0 & 1/2 \\end{matrix}\\right]$\n",
    "\n",
    "$E_2$ = $E_2$ (This will swap the rows back)\n",
    "\n",
    "$E_3$ = $\\left[\\begin{matrix} 1& 0 & 0  \\\\ 0 & 1 & 0  \\\\ 0 & -2 & 1 \\end{matrix}\\right]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a51072e-97a6-4f70-a72c-06f7c1673211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_1A = \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [14 16 18]]\n",
      "\n",
      "E_2A = \n",
      " [[1 2 3]\n",
      " [7 8 9]\n",
      " [4 5 6]]\n",
      "\n",
      "E_3A = \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [15 18 21]]\n",
      "\n",
      "E_1A_undo = \n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "\n",
      "E_2A_undo = \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "E_3A_undo = \n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "e_1 = [[1,0,0],[0,1,0],[0,0,2]]\n",
    "e_2 = [[1,0,0],[0,0,1],[0,1,0]]\n",
    "e_3 = [[1,0,0],[0,1,0],[0,2,1]]\n",
    "A = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "\n",
    "e_1A = np.dot(e_1, A)\n",
    "e_2A = np.dot(e_2, A)\n",
    "e_3A = np.dot(e_3, A)\n",
    "\n",
    "print(f'E_1A = \\n {e_1A}\\n')\n",
    "print(f'E_2A = \\n {e_2A}\\n')\n",
    "print(f'E_3A = \\n {e_3A}\\n')\n",
    "\n",
    "# Undo the operations\n",
    "\n",
    "e_1_undo = [[1,0,0],[0,1,0],[0,0,1/2]]\n",
    "e_2_undo = e_2\n",
    "e_3_undo = [[1,0,0],[0,1,0],[0,-2,1]]\n",
    "\n",
    "e_1A_undo = np.dot(e_1_undo, e_1A)\n",
    "e_2A_undo = np.dot(e_2_undo, e_2A)\n",
    "e_3A_undo = np.dot(e_3_undo, e_3A)\n",
    "\n",
    "print(f'E_1A_undo = \\n {e_1A_undo}\\n')\n",
    "print(f'E_2A_undo = \\n {e_2A_undo}\\n')\n",
    "print(f'E_3A_undo = \\n {e_3A_undo}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f617f10b-d67a-4290-9897-06616943ef8b",
   "metadata": {},
   "source": [
    "### LU Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459db0ae-63fd-47a2-a81d-801b6bf02130",
   "metadata": {},
   "source": [
    "Alternative way to solve a linear system based on Guassian elimination but you don't have to worry about the vector of constants $b$ to solve. If you have a really ugly $b$, then you can use LU factorization to perform the operations just using the coefficient matrix. \n",
    "\n",
    "Theorem: If Gaussian Elimination succeeds in row-reducing $A$ to $U$ using only Type 3 operations, then $A$ has a factorization $A=LU$ where $L$ is unit lower triangular and $U$ is upper triangular with non-zero diagonal entries.\n",
    "\n",
    "$L = $$\\left[\\begin{matrix} 1 & 0 & 0 & 0 & 0 \\\\ x & 1 & 0 & 0 & 0  \\\\ x & x & 1 & 0 & 0 \\\\\n",
    "x &x & x & 1 & 0 \\\\ x & x & x & x & 1 \\end{matrix}\\right]$ (1's on the diagonal, non-zero entries in the lower half, zeros in the upper half)\n",
    "\n",
    "$U = $$\\left[\\begin{matrix} x & x & x & x & x \\\\ 0 & x & x & x & x  \\\\ 0& 0 & x & x & x \\\\\n",
    "0 &0 & 0 & x & x \\\\ 0 & 0 & 0 & 0 & x \\end{matrix}\\right]$ (0's on the lower half, non-zero entries in the upper diagonal and diagonal)\n",
    "\n",
    "We will write $A$ as a product of $L$ and $U$. $U$ is the result of Guassian elimination. $L$ is equal to the matrix that undoes all the row operations ($L$ comes from looking at all the row operations that have been performed).\n",
    "\n",
    "Not every matrix has an $LU$ factorization. \n",
    "\n",
    "Example:\n",
    "\n",
    "Step 1: Use Gaussian elimination on coefficient matrix\n",
    "\n",
    "$A = $$\\left[\\begin{matrix} 1 & 1 & 1 \\\\ -1 & 1 & 1 \\\\ 2 & -1 & 1 \\\\\\end{matrix}\\right]$ \n",
    "\n",
    "$Row_2 \\leftarrow Row_2+Row_1$\\\n",
    "$Row_3 \\leftarrow Row_3-2Row_1$\n",
    "\n",
    "$A = $$\\left[\\begin{matrix} 1 & 1 & 1 \\\\ -1 & 1 & 1 \\\\ 2 & -1 & 1 \\\\\\end{matrix}\\right]$ \n",
    "$\\rightarrow $$\\left[\\begin{matrix} 1 & 1 & 1 \\\\ 0 & 2 & 2 \\\\ 0 & -3 & -1 \\\\\\end{matrix}\\right]$\n",
    "\n",
    "$Row_3 \\leftarrow Row_3+(3/2)Row_1$\\\n",
    "$\\left[\\begin{matrix} 1 & 1 & 1 \\\\ 0 & 2 & 2 \\\\ 0 & -3 & -1 \\\\\\end{matrix}\\right]$$\\rightarrow $$\\left[\\begin{matrix} 1 & 1 & 1 \\\\ 0 & 2 & 2 \\\\ 0 & 0 & 2 \\\\\\end{matrix}\\right] = U$\n",
    "\n",
    "To get $L$, need to look at the row operations that have been performed:\n",
    "\n",
    "$Row_2 \\leftarrow Row_2+Row_1$\\\n",
    "$Row_3 \\leftarrow Row_3-2Row_1$\\\n",
    "$Row_3 \\leftarrow Row_3+(3/2)Row_1$\n",
    "\n",
    "You look at what the multiplier was that was needed in order to zero out the coefficient and take the negative of that. \n",
    "\n",
    "$l_{32} = -(3/2)$ (since 3/2 was used in the last row operation)\\\n",
    "$l_{31} = 2$ (since -2 was used in the second row operation)\\\n",
    "$l_{21} = -1$ (since 1 was used in the first row operation)\n",
    "\n",
    "$L = \\left[\\begin{matrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 2 & -(3/2) & 1 \\\\\\end{matrix}\\right]$\n",
    "\n",
    "Check $LU = A$\n",
    "\n",
    "$\\left[\\begin{matrix} 1 & 0 & 0 \\\\ -1 & 1 & 0 \\\\ 2 & -(3/2) & 1 \\\\\\end{matrix}\\right]\n",
    "* \n",
    "\\left[\\begin{matrix} 1 & 1 & 1 \\\\ 0 & 2 & 2 \\\\ 0 & 0 & 2 \\\\\\end{matrix}\\right]\n",
    "= \n",
    "\\left[\\begin{matrix} 1 & 1 & 1 \\\\ -1 & 1 & 1 \\\\ 2 & -1 & 1 \\\\\\end{matrix}\\right]$ \n",
    "\n",
    "Importance - If an $LU$ factorization exists, it makes it efficient to solve any system of the form $Ax=b$ using $LUx = b$. You do this in 2 steps:\n",
    "\n",
    "1) Solve $Ly = b$ using forward substitution to solve for $y$ ($b$ is known)\n",
    "2) Solve $Ux = y$ using backward substitution\n",
    "\n",
    "We're looking for methods that help us solve linear systems more efficiently. These two methods $Ly = b$ and $Ux = y$ solve in $n^2$ which is significantly faster for a large system. The caveat is you need the $LU$ factorization which requires Gaussian elimination which take $n^3$. In some cases, it's easy to get $LU$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fa34296a-d980-41f8-a483-0f5407cf3ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_answer = \n",
      " [[ 1.  1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [ 2. -1.  1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = [[1,1,1],[-1,1,1],[2,-1,1]]\n",
    "L = [[1,0,0],[-1,1,0],[2,-(3/2),1]]\n",
    "U = [[1,1,1],[0,2,2],[0,0,2]]\n",
    "\n",
    "A_answer = np.dot(L, U)\n",
    "\n",
    "print(f'A_answer = \\n {A_answer}\\n')\n",
    "assert np.array_equal(A, A_answer)\n",
    "\n",
    "assert np.array_equal(gaussian_elimination(A),U)\n",
    "\n",
    "def get_L(coefficients):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4e225-1c11-4bb4-91f6-831f292389fd",
   "metadata": {},
   "source": [
    "### Matrix Inverses\n",
    "Previously, we focused on solving with efficiency in mind. Inverse matrixes are nice algebraic ways to solve matrices. Computationally, it's very expensive. \n",
    "\n",
    "Definition: The inverse of a matrix $A \\in \\mathbb{R}^{m*n}$ (if it exists) is a matrix $B \\in \\mathbb{R}^{m*n}$ such that $BA$ = $I_n$ = $AB$\n",
    "\n",
    "$I_n = \\left[\\begin{matrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\\\end{matrix}\\right] \\in \\mathbb{R}^{m*n}$\n",
    "\n",
    "If such a $B$ exists, it is unique and it is denoted by $A^{-1}$\n",
    "\n",
    "To compute $A^{-1}$, row-reduce the augmented matrix $[A | I_n]$ until the left hand square is $I_n$ then the right hand square will be $A^{-1}$ \n",
    "\n",
    "Example: \n",
    "\n",
    "$A = \\left[\\begin{matrix} 1 & 2 \\\\ 3 & 4 \\end{matrix}\\right]$\\\n",
    "$I_n = \\left[\\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}\\right]$\n",
    "\n",
    "$[A | I_n]$ = $\\left[\\begin{matrix} 1 & 2 &|&1&0 \\\\ 3 & 4 &|&0&1 \\end{matrix}\\right] \\rightarrow $\n",
    "\n",
    "Now we need to row-reduce.\n",
    "1) $Row_2 \\leftarrow Row_2 - 3Row_1$ = $\\left[\\begin{matrix} 1 & 2 &|&1&0 \\\\ 0 & -2 &|&-3&1 \\end{matrix}\\right] $\n",
    "2) $Row_1 \\leftarrow Row_1 + Row_2$ = $\\left[\\begin{matrix} 1 & 0 &|&-2&1 \\\\ 0 & -2 &|&-3&1 \\end{matrix}\\right] $\n",
    "3) $Row_2 \\leftarrow Row_2 -(1/2)Row_2$ = $\\left[\\begin{matrix} 1 & 0 &|&-2&1 \\\\ 0 & 1 &|&3/2&-1/2 \\end{matrix}\\right] $\n",
    "\n",
    "$A^{-1} = \\left[\\begin{matrix} -2&1 \\\\ 3/2&-1/2 \\end{matrix}\\right] $\n",
    "\n",
    "Check $AA^{-1} = I_n$\n",
    "\n",
    "$\\left[\\begin{matrix} 1 & 2 \\\\ 3 & 4 \\end{matrix}\\right]\n",
    "* \n",
    "\\left[\\begin{matrix} -2&1 \\\\ 3/2&-1/2 \\end{matrix}\\right] \n",
    "= \n",
    "\\left[\\begin{matrix} 1 & 0 \\\\ 0 & 1 \\end{matrix}\\right]$\n",
    "\n",
    "**Importance:** \n",
    "If you know $A^{-1}$ you can solve for $x$ in $Ax = b$ very quickly:\n",
    "\n",
    "$Ax = b$\\\n",
    "$A^{-1}Ax = A^{-1}b$ (multiply both sides by the $A^{-1})$\\\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;($A^{-1}A$ is just the identity matrix, which if multiplied by $x$, just gives $x$)\\\n",
    "$x = A^{-1}b$ (Shows that multiplying $b$ by $A^{-1}$ gives us $x$)\n",
    "\n",
    "This seems like the easiest algebraic way to solve linear systems but it's impractical for solving large linear systems because of performance. As a conceptual method, it's a nice way to solve a linear system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e6a417f7-688e-42c2-bfb4-f5322935a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In_answer = \n",
      " [[1. 0.]\n",
      " [0. 1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = [[1,2],[3,4]]\n",
    "Ai = [[-2,1],[3/2,-1/2]]\n",
    "In = [[1,0],[0,1]]\n",
    "\n",
    "In_answer = np.dot(A, Ai)\n",
    "\n",
    "print(f'In_answer = \\n {In_answer}\\n')\n",
    "assert np.array_equal(In, In_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1e3e4c-b5a8-492d-9259-0a24c5e4fbf4",
   "metadata": {},
   "source": [
    "### Iterative Solution Methods\n",
    "\n",
    "For large linear systems, direct methods can be too inefficient. Iterative methods give an approximate solution and work by first guessing a solution for $x$, then applying a sequence of operations to improve this guess. The method halts when successive approximations are sufficiently similar. \n",
    "\n",
    "Examples:\n",
    "* Jacobi Method\n",
    "  1) Guess $x^{(0)}$\n",
    "  2) Repeat for $k = 1, 2,...$ until convergence\\\n",
    "  For $i=1$ to $n$\\\n",
    "  &nbsp;&nbsp; Set $x_i^{(k+1)} = (b_i - \\sum_{j!=i}^na_{ij}x_j^k) / a_{ii}$ (Similar to the formula used in backward substitution. But in backward subtitution, $x_j$ is the true solution but in Jacobi, $x_j$ is an approximation. If using Jacobi, $x_j$ happens to be the true solution, which can happen for some matrices, $x_i^{k+1}$ is also the true solution.)\n",
    "* Gauss-Seidel Method - Similar to Jacobi method\n",
    "  1) Guess $x^{(0)}$\n",
    "  2) Repeat for $k = 1, 2,...$ until convergence\\\n",
    "  For $i=1$ to $n$\\\n",
    "  &nbsp;&nbsp; Set $x_i^{(k+1)} = (b_i - \\sum_{j<i}^na_{ij}x_j^{k+1} - \\sum_{j>i}^na_{ij}x_j^{k}) / a_{ii}$ (Gauss-Seidel uses previously known values of $x_j^{k+1}$ to converge faster if done sequentially)\n",
    "* SOR Methods - Successive Over-relaxation Methods - Modification of Gauss-Seidel that uses weights.\\\n",
    "  1) Guess $x^{(0)}$\n",
    "  2) Repeat for $k = 1, 2,...$ until convergence\\\n",
    "  For $w \\in [0,2]$\\\n",
    "  $x_i^{k+1} = (1-w)x_i^k + w((b_i - \\sum_{j!=i}^na_{ij}x_j^k) / a_{ii})$\\\n",
    "  * Weighting parameter is a general method for taking an iterative method that's not converging fast enough and speeding it up. A higher $w$ moves you away from the previous solution faster. A lower $w$ will move you towards a new solution more slowly. \n",
    "  * These are pretty good practical methods for solving linear systems in a reasonable amount of time. \n",
    "  \n",
    "Comparison:\n",
    "* Jacobi method can be parallelized (no knowledge of previous values is needed)\n",
    "* Gauss-Seidel can't be parallelized because you need the value you just computed to compute the next value. If you're updating $x_i^{k+1}$ sequentially, GS converges faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59391942-2442-45d1-a75b-1d07767625a1",
   "metadata": {},
   "source": [
    "### Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba625f8-e50d-4762-a487-d5f592e3a4c2",
   "metadata": {},
   "source": [
    "High-Level Objectives\n",
    "* Define linear systems and explain how to represent them\n",
    "* Solve linear systems using:\n",
    "  * E.g., Gaussian elimination with backward substitution\n",
    "  * LU factorization of the coefficient matrix\n",
    "  * Inverse of the coefficient matrix\n",
    "  * An iterative method\n",
    "  \n",
    "Linear Systems: Expressions\n",
    "* List of multivariable equations\n",
    "* Single matrix-vector equation\n",
    "* Augmented matrix\n",
    "\n",
    "Linear Systems: Types\n",
    "* Overconstrained\n",
    "* Perfectly constrained\n",
    "* Underconstrained\n",
    "* Focus is on square systems\n",
    "  * Underconstrained systems can be made square by adding rows of zeroes.\n",
    "  * Overconstrained systems can approximate a square system indirectly by solving related square systems.\n",
    "  \n",
    "Linear Systems: Solutions\n",
    "* Direct methods rely on changing the system to a simpler one with the same solution\n",
    "* E.g., Gaussian elimination with backward substitution\n",
    "* Gaussian elimination reduces a system to upper triangular form using elementary row operations.\n",
    "* Backward substitution solves iteratively for $x$ in the order $x_n,...,x_1$.\n",
    "\n",
    "Elementary Matrices\n",
    "* Row operations can be performed (or unperformed) by using matrix multiplication.\n",
    "\n",
    "Linear System Solution: LU Factorization\n",
    "* If Gaussian elimination doesn't require row swaps, the coefficient matrix has an LU factorization.\n",
    "  * L: lower triangular matrix\n",
    "  * U: upper triangular matrix with nonzero diagonals\n",
    "* If there is an LU factorization for A, solvingAx=b can be done by using forward and backward substitution.\n",
    "* L and U can be stored as part of the Gaussian elimination algorithm without additional computation.\n",
    "\n",
    "Linear System Solution: Matrix Inverses\n",
    "* An inverse of matrix $A$ (if it exists) is a matrix $B$ so that $AB=BA=I$.\n",
    "* Computed by reducing an augmented matrix $[A|I]$ to the form $[I|B]$.\n",
    "  * If it works, $B=A^{−1}$\n",
    "* If $A$ has an inverse, $Ax=b$ has the unique solution $A^{−1}b$.\n",
    "\n",
    "Linear System Solution: Iterative Methods\n",
    "* Guess a solution, then perform operations to improve the guess.\n",
    "* Jacobi Method\n",
    "* Gauss-Seidel Method\n",
    "* SOR (Successive Over-relaxation) Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba7bac5-925b-4d77-8ad8-bf5b462664e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
