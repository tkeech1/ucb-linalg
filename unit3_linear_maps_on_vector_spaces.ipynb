{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a602aa6b-21d0-4e05-9114-7bcad2164bde",
   "metadata": {},
   "source": [
    "## Unit 3 - Linear Maps on Vector Spaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0392d-ab0a-408f-a6c9-69e3a57eb0ed",
   "metadata": {},
   "source": [
    "### Vector Spaces\n",
    "\n",
    "Vector spaces are a generalization of the properties of real vectors. Formally, a vector space is a set $V$ together with:\n",
    "* vector addition $+:VxV \\rightarrow V$\n",
    "* scalar multiplication $ \\cdot : \\mathbb{R} x V \\rightarrow V $\n",
    "* additive inverse $-: V \\rightarrow V $\n",
    "* zero vector $ 0 \\in V$\n",
    "\n",
    "That satsfies the following axioms:\n",
    "\n",
    "$\\forall x,y,z \\in V$ and $\\forall a,b \\in \\mathbb{R}$\n",
    "\n",
    "1) $+$ is associative: $x+(y+z) = (x+y)+z$\n",
    "2) $+$ is commutative: $x+y = y+x$\n",
    "3) $0$ is an additive identity: $x+0 = x = 0+x$\n",
    "4) $-$ is an inverse for $+$: $x+(-x) = 0 = -x + x $\n",
    "\n",
    "$<V, + , -, 0>$ is an abelian group\n",
    "\n",
    "Scalar multiplication respects:\n",
    "\n",
    "5) vector addition: $a \\cdot (x+y) = a \\cdot x + a \\cdot y$\n",
    "6) real number addition: $(a + b) \\cdot x = a \\cdot x + b \\cdot x$\n",
    "7) real number multiplication: $(a \\cdot_{\\mathbb{R}} b) \\cdot_{sm} x = a \\cdot_{sm} (b \\cdot_{sm} x)$\n",
    "   NOTE: $a \\cdot b$ is multiplication by real numbers (since $a, b \\in \\mathbb{R}$). Multiplying by $x$ is scalar multiplication since $x \\in V$. On the right hand side, the $a \\cdot b$ is also scalar multiplication.\n",
    "8) $1_{\\mathbb{R}}$: $1_{\\mathbb{R}} \\cdot x = x$ NOTE: without this axiom, you could have a vector space where scalar multiplication trivially assigned everything to zero and this guarntees that doesn't happen. \n",
    "\n",
    "The remainder of the unit relies on these axioms. \n",
    "\n",
    "$\\mathbb{R}^2$ is all possible real-valued 2-tuples - a 2-dimensional real coordinate space\n",
    "$\\mathbb{R}^3$ is all possible real-valued 3-tuples - a 3-dimensional real coordinate space\n",
    "$\\mathbb{R}^n$ is all possible real-valued n-tuples - a n-dimensional real coordinate space\n",
    "\n",
    "Protoypical Example of a Vector Space:\n",
    "\n",
    "$<\\mathbb{R}^n, +_{\\mathbb{R}^n}, \\cdot_{sm}, -_{\\mathbb{R}^n}, 0_{\\mathbb{R}}>$\n",
    "\n",
    "Other Examples of Vector Spaces:\n",
    "\n",
    "* $\\mathbb{R}^{n*m}$ : The set of real $mxn$ matrices is an example of a vector space because you add them, scalar multiply them, you have additive inverses for each of them, and a 0 matrix. Since those operations satisfy the 8 axioms, the set of real $mxn$ matrices is a vector space.\n",
    "* $L(\\mathbb{R}^n \\rightarrow \\mathbb{R}^m)$ : This is linear maps (functions) from $\\mathbb{R}^n to \\mathbb{R}^m$. This is also a vector space because it satisfies the axioms. \n",
    "* $\\mathbb{R}[x]_{<=n}$ : The set of all polynomial functions with real number coefficients where the degree of the polynomial is <= n. \n",
    "* $\\mathbb{R}[x]$ is an example of a vector space that is not finite dimensional. It is the set of all polynomial functions with real number coefficients. It can be arbitrarily long. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c27db8f-1579-4275-917d-0fcd1af60daa",
   "metadata": {},
   "source": [
    "### Linear Combinations\n",
    "\n",
    "**Example from Khan Academy**\n",
    "\n",
    "$v_1, v_2, .. v_n \\in \\mathbb{R}^n$\n",
    "\n",
    "A linear combination of the vectors $v$ means we scale these vectors by constants $c \\in \\mathbb{R}$:\n",
    "\n",
    "$c_1v_1 + c_2v_2 + ... + c_nv_n$\n",
    "\n",
    "Example of a Linear Combination\n",
    "\n",
    "$a = \\left(\\begin{matrix} 1 \\\\ 2 \\end{matrix}\\right)$\n",
    "$b = \\left(\\begin{matrix} 0 \\\\ 3 \\end{matrix}\\right)$\n",
    "\n",
    "$3a + 2b = \\left(\\begin{matrix} 3 \\\\ 0 \\end{matrix}\\right)$ is one linear combination of $a$ and $b$.\n",
    "\n",
    "The set of all linear combinations is the **span**. In this case, Span$(a, b) = \\mathbb{R}^2$ but there are many cases where this isn't true. \n",
    "\n",
    "A case where this is not true is:\n",
    "$a = \\left(\\begin{matrix} 2 \\\\ 2 \\end{matrix}\\right)$\n",
    "$b = \\left(\\begin{matrix} -2 \\\\ -2 \\end{matrix}\\right)$\n",
    "\n",
    "Here, Span($a,b$) falls along a single line because they are colinear. \n",
    "\n",
    "**UCB**\n",
    "\n",
    "Suppose $V$ is a vector space over $\\mathbb{R}$ and $U \\subseteq V$\n",
    "\n",
    "Define \n",
    "\n",
    "$Span(U) = {\\sum_{k=1}^n a_ku_k: a_k \\in \\mathbb{R}, u_k \\in U$}$ (The set of all linear combinations of vectors in $U$)\\\n",
    "\n",
    "We always have $Span(U) \\subseteq V$\n",
    "\n",
    "Definition - We say \"$U$ spans $V$\" if $Span(U) = V$\n",
    "\n",
    "Definition - We say $V$ is finite-dimensional if there exists a finite subset $U$ \\subseteq such that $U$ spans $V$\n",
    "\n",
    "For $U$ to span $V$ there has to be some way to get every element of the vector space by taking linear combination of the elements of $U$.\n",
    "\n",
    "Examples:\n",
    "\n",
    "$\\mathbb{R}^3$ is finite dimensional because the set of vectors:\\\n",
    "$U$ =\n",
    "$\\Bigg\\{\n",
    "\\left(\\begin{matrix} 1 \\\\ 0 \\\\ 0 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\\\ 0 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 0 \\\\ 0 \\\\ 1 \\end{matrix}\\right)\n",
    "\\Bigg\\}\n",
    "$ spans $V$\n",
    "\n",
    "Every vector $v \\in V$ $\\left(\\begin{matrix} a_1 \\\\ a_2 \\\\ a_3 \\end{matrix}\\right)$ can be expressed as: \\\n",
    "$a_1 \\cdot \\left(\\begin{matrix} 1 \\\\ 0 \\\\ 0 \\end{matrix}\\right) + a_2 \\cdot \\left(\\begin{matrix} 0 \\\\ 1 \\\\ 0 \\end{matrix}\\right) + a_3 \\cdot \\left(\\begin{matrix} 0 \\\\ 0 \\\\ 1 \\end{matrix}\\right)$ (Every vector in $V$ can be writte as a linear combination of elements of $U$ so $U$ spans $V$, $U$ spans $\\mathbb{R}^3$, and since a finite set spans $U$, $U$ is finite dimensional.)\n",
    "\n",
    "Also: \n",
    "\n",
    "$\\Bigg\\{\n",
    "\\left(\\begin{matrix} 0 \\\\ 0 \\\\ 0 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 0 \\\\ 0 \\\\ 1 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\\\ 0 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\\\ 1 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 1 \\\\ 0 \\\\ 0 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 1 \\\\ 0 \\\\ 1 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 1 \\\\ 1 \\\\ 0 \\end{matrix}\\right)\n",
    "\\left(\\begin{matrix} 1 \\\\ 1 \\\\ 1 \\end{matrix}\\right)\n",
    "\\Bigg\\}$ spans $V$\n",
    "\n",
    "Example of a not finite dimensional $V$\n",
    "\n",
    "$\\mathbb{R}[x]$ is not finite dimensional ($\\mathbb{R}[x]$ is polynomials in one variable with coefficients in $\\mathbb{R}$) \n",
    "\n",
    "It contains {$1,x^2,x^3,x^4,x^5,...$} which is an infinite set $\\in \\mathbb{R}[x]$) - There's no way to get each of these elements as a linear combination from a finite subset of real polynomials. For example, if you have a finite set of polynomials, you can only have up to the maximum degree of those polynomials. So if the maximum degree is 1000, you can never have $x^1001$ as a linear combination of polynomials whose degree is $<1000$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f598e-c9f6-4816-b007-1055a49001c8",
   "metadata": {},
   "source": [
    "### Linear Independence and Bases\n",
    "\n",
    "**Khan Academy Example:**\n",
    "\n",
    "The span of $\\Bigg\\{\n",
    "\\left[\\begin{matrix} 2 \\\\ 3 \\end{matrix}\\right],\n",
    "\\left[\\begin{matrix} 4 \\\\ 6 \\end{matrix}\\right]\n",
    "\\Bigg\\}$ is all the points of a single line since [4,6] is a multiple of [2,3]\n",
    "\n",
    "We say they are colinear so their span reduces to a single line. You can't represent everyting in $\\mathbb{R}^2$ with these two vectors. We call this a linearly dependent set. The same goes for any vectors with number of dimensions $\\mathbb{R}^n$\n",
    "\n",
    "**UCB:**\n",
    "\n",
    "Suppose $V$ is a vector space over $\\mathbb{R}$ and that $U \\subseteq V$\n",
    "\n",
    "Define: We say that U is linearly dependent over $\\mathbb{R}$ if there exists nonzero $a_1..a_n \\in \\mathbb{R}$ and nonzero $u_1..u_m \\in U$ with $\\sum_{k=1}^na_ku_k = 0$\n",
    "\n",
    "This means there is some nonzero linear combination of these vectors that sum to 0\n",
    "\n",
    "Define: We say $U$ is linearly independent over $\\mathbb{R}$ if $U$ is not linearly dependent, equivalently:\n",
    "\n",
    "* The usable definition for linearly independent is: Whenever we have $0 = \\sum_{k=1}^na_ku_k = 0$ for nonzero $u_1..u_n \\in U$ this implies a_k = 0 for $k=1..n$\n",
    "\n",
    "**Khan Academy Example:**\n",
    "\n",
    "Is the following set of vectors $U$ linearly dependent or linearly independent?\n",
    "\n",
    "$U$ = $\\Bigg\\{\n",
    "\\left[\\begin{matrix} 2 \\\\ 1 \\end{matrix}\\right],\n",
    "\\left[\\begin{matrix} 3 \\\\ 2 \\end{matrix}\\right]\n",
    "\\Bigg\\}$\n",
    "\n",
    "For $U$ to be linearly dependent, there must be some nonzero $c_1, c_2$ such that\n",
    "\n",
    "$c_1 \\cdot \\left[\\begin{matrix} 2 \\\\ 1 \\end{matrix}\\right] + c_2 \\cdot \\left[\\begin{matrix} 3 \\\\ 2 \\end{matrix}\\right] = 0$\n",
    "\n",
    "If the only way to satisfy the above equation is to set $c_1, c_2$ to zero, then they are linearly independent. \n",
    "\n",
    "$2c_1 + 3c_2 = 0$\\\n",
    "$c_1 + 2c_2 = 0$\n",
    "\n",
    "$c_1 + 3/2c_2 = 0$ (multiply top equation by $1/2$)\\\n",
    "$c_1 + 2c_2 = 0$\n",
    "\n",
    "$-1/2c_2 = 0$ (subtract the bottom equation from the top)\\\n",
    "$c_2 = 0$\n",
    "\n",
    "$c_1 + 2(0) = 0 $ (substitute $c_2$ into the original equation)\\\n",
    "$c_1 = 0$\n",
    "\n",
    "$U$ is linearly independent because the only solution to this equation requires $c_1, c_2$ to be zero. This also means that Span($U$) $= \\mathbb{R}^2$\n",
    "\n",
    "#### Bases\n",
    "Define: $U$ is a basis for $V$ if:\n",
    "1) $U$ spans $V$\n",
    "2) $U$ is linearly indepndent over $\\mathbb{R}$\n",
    "\n",
    "#### What are we saying with all this?\n",
    "* Linear Combinations are a way to combine $n$ vectors to produce another vector\n",
    "* Spans define reachability criteria and address the question - Can we get all elements in the vector space?\n",
    "* Linear independence says that there's only one way to get the 0 vector by taking a linear combination of the set.  \n",
    "* If we have a set that meets both span and linear independence, it's a bases.\n",
    "\n",
    "Examples:\n",
    "\n",
    "**Example of linearly dependent**\n",
    "\n",
    "$\\Bigg\\{\n",
    "\\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 1 \\\\ 0 \\end{matrix}\\right)\n",
    "\\Bigg\\} = U \\subseteq \\mathbb{R}^2$ is linearly dependent. For this to be true, we need to be able to write the 0 vector as a combination of these three vectors using non-zero coefficients. One way to do that is:\n",
    "\n",
    "$1 \\cdot \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right) + (-1) \\cdot \\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right) + (-1) \\cdot \\left(\\begin{matrix} 1 \\\\ 0 \\end{matrix}\\right)  = 0 $\n",
    "\n",
    "**Example of linearly independent**\n",
    "\n",
    "$\\Bigg\\{\n",
    "\\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right)\n",
    "\\Bigg\\} = U \\subseteq \\mathbb{R}^2$ is linearly independent. How can we show that?\n",
    "\n",
    "Suppose we have a linear combination of these and it's equal to zero\n",
    "\n",
    "Suppose $a_1 \\cdot \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right) + a_2 \\cdot \\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right) = \\left(\\begin{matrix} a_1 \\\\ a_1 + a_2 \\end{matrix}\\right) = \\left(\\begin{matrix} 0 \\\\ 0 \\end{matrix}\\right)$\n",
    "\n",
    "We can solve this small linear system and find that $a_1 = 0$ and $a_2 = 0$. This meets the definition of linearly independent because the definition states that any time we get 0 as a linear combination of vectors, then the only way for that to happen is for the coefficients to be zero. \n",
    "\n",
    "$\\Bigg\\{\n",
    "\\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right)\n",
    "\\Bigg\\} = U \\subseteq \\mathbb{R}^2$ is a bases for $\\mathbb{R}^2$\n",
    "\n",
    "To show that, let $\\left(\\begin{matrix} a_1 \\\\ a_2 \\end{matrix}\\right) \\in \\mathbb{R}^2$ and now we need to show we can get $\\left(\\begin{matrix} a_1 \\\\ a_2 \\end{matrix}\\right)$ as a linear combination of $\\Bigg\\{\n",
    "\\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right),\n",
    "\\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right)\n",
    "\\Bigg\\}$ \n",
    "\n",
    "$a_1 \\cdot \\left(\\begin{matrix} 1 \\\\ 1 \\end{matrix}\\right) + (a_2 - a_1) \\cdot \\left(\\begin{matrix} 0 \\\\ 1 \\end{matrix}\\right) = \\left(\\begin{matrix} a_1 \\\\ a_2 \\end{matrix}\\right)$ - This shows that any vector in $\\mathbb{R}^2$ can be written as a linear combination of the vectors $[1,1]$ and $[0,1]$ therefore this set spans the whole vector space and is also a bases. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abd4b78-b0bc-479f-9893-16458ba081b7",
   "metadata": {},
   "source": [
    "### The Dimension Theorem\n",
    "\n",
    "A fundamental result that says that the cardinality of any two bases of a vector space is the same. \n",
    "\n",
    "Theorem - Any two bases of a vector space have the same cardinality.\n",
    "\n",
    "Definition (based on the theorem) - The dimension of a vector space is the unique cardinality of any basis. (This says that bases for a given vector space must have the same number of elements - you can't have one base that has 2 elements and another that has 3)\n",
    "\n",
    "Example - The dimension of $\\mathbb{R}^n$ is $n$ since {$e_1, e_2,... e_n$} is a basis which has $n$ elements. So, every basis of $\\mathbb{R}^n$ has $n$ elements. \n",
    "\n",
    "**Proof Sketch:**\n",
    "\n",
    "Lemma: If $T$ is linearly independent over $\\mathbb{R}$ and $S$ spans $V$ and $T, S \\subseteq V$ the $|T| <= |S|$ (cardinality of T <= cardinality of S)\n",
    "\n",
    "Enumerate $T = t_1, t_2, t_3, ...$ (not assuming this is finite)\n",
    "\n",
    "Since $S$ spans $V$, we can write:\n",
    "\n",
    "$t_1 = \\sum_{k=1}^ma_ks_k$ with each $s_k \\in S$ and each $a_k != 0 \\in \\mathbb{R}$\n",
    "\n",
    "Solve for $s_1$ \n",
    "\n",
    "$s_1 = \\frac{t_1 - \\sum_{k=1}^ma_ks_k}{a_1}$\n",
    "\n",
    "Bucket analogy - an injective function from $T$ into $S$ - For each $t_i$ I can always find an $s_i in S$ but not in $T$ such that when I write $t_i = \\sum_{k=1}^na_ku_k$ with $u_k \\in S'$ then there is some $s_i \\in S$ but not in T that I can pop out of the bucket.\n",
    "\n",
    "TODO - ? Explain this better\n",
    "\n",
    "Now, we need to prove the dimension theorem from the above Lemma. Suppose $B_1, B_2$ are both bases. The Lemma says that the Linearly Independent set can never be bigger than the Spanning set. \n",
    "\n",
    "We can think of this in 2 ways:\n",
    "1) $B_1$ is linearly independent and $B_2$ spans $V$ which implies $|B_1 <= |B_2|$\n",
    "2) $B_2$ is linearly independent and $B_1$ spans $V$ which implies $|B_2 <= |B_1|$\n",
    "\n",
    "**The Main Idea** - For a given vector space, the number of elements in a basis is unique and is an invariant of that vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf042fd-e8e0-4903-be0c-c51ebd47e2c2",
   "metadata": {},
   "source": [
    "#### Representations of Linear Maps\n",
    "\n",
    "We will take a linear map of a vector space and represent it as a matrix. Representations of linear maps of vector spaces depend on a basis. We also had to derive the dimension theorem so we would know that the size of our matrix is fixed. \n",
    "\n",
    "Suppose $U, V$ are vector spaces over $\\mathbb{R}$\n",
    "\n",
    "Definition: A linear map (aka. function) from $U$ to $V$ is a function $T: U \\rightarrow V$ satisfying the linear condition for all $u_1, u_2 \\in U$ and $a \\in \\mathbb{R}$:\n",
    "* $T(u_1 + u_2) = T(u_1) + T(u_2)$\n",
    "* $T(au_1)  = aT(u_1)$\n",
    "\n",
    "The set of all linear maps from $U$ into $V$ is denoted by $L(U,V)$\n",
    "\n",
    "In Unit 1, we saw that if $U = \\mathbb{R}^n$ and $W = \\mathbb{R}^m$ then every linear map in $L(\\mathbb{R}^n,\\mathbb{R}^m)$ can be represented uniquely as a matrix $A \\in \\mathbb{R}^{m*n}$\n",
    "\n",
    "* For $\\mathbb{R}^n$, we have a natural notion of a basis ($e_1, e_2, e_3, ... e_n$) which have nice geometric properties but we can't quite use those properties yet. For now, we stick with addition and scalar multiplication.\n",
    "\n",
    "Theorem:\n",
    "\n",
    "If $u_1, u_2, ... u_n$ is a basis for $U$ and $w_1, w_2,... w_n$ is a basis for $W$ and $T \\in L(U, W)$ ($T$ is a linear map from $U$ into $W$) then $T$ has a matrix representation in the bases $u_1, u_2, ... u_n$ $w_1, w_2,... w_n$ denoted $M(T, (u_1, u_2, ... u_n), (w_1, w_2,... w_n)) \\in \\mathbb{R}^{m*n}$\n",
    "\n",
    "* This is analagous to the situation from Unit 1 where the vector spaces were $\\mathbb{R}^n$ and $\\mathbb{R}^m$ and we got an $\\mathbb{R}^{m*n}$ matrix\n",
    "\n",
    "The coefficients are $[a_{ij}]_{i=1..m,j=1...m}$ where $T(u_j) = a_{ij}w_i$\n",
    "* This is slightly different than the definition for real matrices we covered in Unit 1: $a_{ij} = <T(u_j),w_i>$ \n",
    "* The Unit 1 definition is not defined yet because we haven't defined inner product on an arbitrary vector space\n",
    "\n",
    "**The Main Idea** - If you have any linear map (function) between two vector spaces and the vector spaces are finite dimensional then, with respect to any fixed bases of those vector spaces, there is a matrix representation of that linear map. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c64404-0e68-4ed4-85d1-4b7d7a014d9f",
   "metadata": {},
   "source": [
    "#### Differentiation as a Linear Map\n",
    "\n",
    "We will construe the calculus differentiation operator as a linear map and represent it as a matrix to show an application of the representation theorem for linear maps\n",
    "\n",
    "Let $V = \\mathbb{R}[x]_{<=3}$ = The set of all polynomials in one variable with coefficients in $\\mathbb{R}$ with degree $<= 3$ (no exponents larger than 3). It can be represented by the set:\n",
    "* {$a_0 + a_1x + a_2x^2 + a_3x^3 : a_0, a_1, a_2, a_3 \\in \\mathbb{R} $}\n",
    "* This is a vector space because:\n",
    "  * It contains the zero vector\n",
    "  * The result of addition lies within the space (additive inverse)\n",
    "  * The result of scalar multiplication lies within the space (scalar multiplication)\n",
    "  \n",
    "What is an examle of a basis for this vector space?\n",
    "\n",
    "Claim: {$1,x,x^2,x^3$} is a basis for $V$. Why?\n",
    "\n",
    "Need to show 2 things:\n",
    "1) That the set spans $V$ (i.e. every polynomial can be written as a linear combination of the elements). This is obvious by the definition. We can get any degree <= 3 polynomial by multiplying each term by its coefficient.\n",
    "2) That the elements are linearly independent. For any linear combination of these elements to equal 0, the only way for that to happen is by setting all coefficients equal to 0. That's also true in this case because if any of the coefficients are non-zero, you won't get the zero polynomial. \n",
    "\n",
    "Let $W = \\mathbb{R}[x]_{<=2}$\n",
    "\n",
    "Define $T:V \\rightarrow W$ by $T(P(x)) = \\frac{d}{dx}P(x)$\n",
    "* $T$ is the derivative of $P(x)$\n",
    "\n",
    "I claim $T \\in L(V, W)$ ($T$ is a linear function from $V \\rightarrow W$) so $T$ must preserve addition and scalar multiplication. We need to check to see if that's true\n",
    "\n",
    "* Addition\n",
    "  * $T(P(x) + Q(x)) = \\frac{d}{dx}(P(x) + Q(x)) = \\frac{d}{dx}P(x) + \\frac{d}{dx}Q(x) = T(P(x)) + T(Q(x))$ (since the derivative operator respects sums)\n",
    "* Scalar Multiplication\n",
    "  * $T(aP(x)) = \\frac{d}{dx}aP(x) = a \\frac{d}{dx}P(x) = aT(P(x))$ (since the derivative respects multiplication)\n",
    "\n",
    "So, $T$ is a linear map. \n",
    "\n",
    "What is the matrix of $T$ in the bases {$1, x, x^2, x^3$} = {$v_1, v_2, v_3, v_4$} of $V$ and {$1, x, x^2$} = {$w_1, w_2, w_3$} of $W$?\n",
    "\n",
    "Use the definition of matrix construction: $T(v_j) = \\sum_{i=1}^ma_{ij}w_i$ (so we will write out what $T$ does to a basis for $v$ in terms of the basis for $w$ and from that set of equations, we can read off the coefficients of the matrix)\n",
    "\n",
    "$T(v_1) = T(1) = \\frac{d}{dx}1 = 0$ (since the derivative of 1 is 0)\n",
    "* There's only one way to write 0 as the linear combination of $a_{ij}w_i$: set all $a_{ij}$ elements to 0. \n",
    "\n",
    "$T(v_2) = T(x) = \\frac{d}{dx}x = 1$ = $w_1$ (so $a_{ij} = 1$)\n",
    "\n",
    "$T(v_3) = T(x^2) = \\frac{d}{dx}x^2 = 2x = 2w_2$ (so $a_{ij} = 2$)\n",
    "\n",
    "$T(v_4) = T(x^3) = \\frac{d}{dx}x^3 = 3x^2 = 3w_3$ (so $a_{ij} = 3$)\n",
    "\n",
    "Since $T: V \\rightarrow W$, $T$ will be a 3x4 matrix. $T(v_1)$ is going to give us the first column of the matrix. $T(v_2)$ gives the second column and so on.\n",
    "\n",
    "$M(T) = \\left[\\begin{matrix} 0&1&0&0 \\\\ 0&0&2&0 \\\\ 0&0&0&3 \\\\ \\end{matrix}\\right]$\n",
    "\n",
    "This is the matrix of the differentiation operator. Let's check this actually works.\n",
    "\n",
    "$P(x) = 7 + 5x - 2x^2 + x^3$\n",
    "\n",
    "Instead of taking the derivative using calculus, we can use linear algebra and the matrix we just created. We represent the polynomial above as a vector of coefficients. \n",
    "\n",
    "$\\left[\\begin{matrix} 0&1&0&0 \\\\ 0&0&2&0 \\\\ 0&0&0&3 \\\\ \\end{matrix}\\right]\n",
    "* \n",
    "\\left(\\begin{matrix} 7 \\\\ 5 \\\\ -2 \\\\ 1 \\end{matrix}\\right)\n",
    "= \n",
    "\\left(\\begin{matrix} 5 \\\\ -4 \\\\ 3 \\end{matrix}\\right)\n",
    "$\n",
    "\n",
    "$\\frac{d}{dx}P(x) = 5 - 4x + 3x^2$\n",
    "\n",
    "Another Example\n",
    "\n",
    "$S: W \\rightarrow V$ by $S(q(x)) = \\int q(x)dx$\n",
    "\n",
    "\\* is indeterminate\n",
    "\n",
    "$M(S) = \\left[\\begin{matrix} *&*&* \\\\ 1&0&0 \\\\ 0&\\frac{1}{2}&0 \\\\ 0&0&\\frac{1}{3} \\end{matrix}\\right]$\n",
    "\n",
    "Note: $T \\circ S = I_w = \\left[\\begin{matrix} 1&0&0 \\\\ 0&1&0 \\\\ 0&0&1 \\end{matrix}\\right]$\n",
    "\n",
    "The composition of $T$ and $S$ is the identity matrix of $W$. This is the Fundamental Theorem of Calculus (If you first integrate, then differentiate, you get back the original result).\n",
    "\n",
    "$S \\circ T = \\left[\\begin{matrix} 0&*&*&* \\\\ 0&1&0&0 \\\\ 0&0&1&0 \\\\ 0&0&0&1 \\end{matrix}\\right]$\n",
    "\n",
    "If you start with a function, take it's derivative and then take its anti-derivative, you don't get back the original function because of the indeterminants. You lose the constant terms. \n",
    "\n",
    "**The Main Idea** - This example shows how you can use linear algebra to do basic calculus operations and it shows how to represent a linear map (function) as a matrix with respect to a basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f542219-91a8-438e-83b7-ce308bf5d414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
